{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mtrTjkdbP4s",
        "outputId": "b952af71-b0eb-407c-b9f1-32fa6e014352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 1.12.1+cu113\n",
            "\u001b[K     |████████████████████████████████| 239.2 MB 1.0 kB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 972 kB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 62.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 29.1 MB 87.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 103 kB 39.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 202 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 43.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 500 kB 39.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 121 kB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 100 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 59.5 MB/s \n",
            "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))\n",
        "\n",
        "!pip install -q dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import time\n",
        "import dgl"
      ],
      "metadata": {
        "id": "GUKrCF2DbbY9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "QV__L4ECbcvE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtxrOMJGbqxz",
        "outputId": "0509b96d-f08d-4361-ed52-b3962e8f7f23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertLMHeadModel,BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce4XS51qbeG-",
        "outputId": "6a279bfe-0f29-4d2b-e8e5-ba4d076fd2a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = [tokenizer.tokenize(sen) for sen in train_df.claim.values] \n",
        "\n",
        "max_lenth = 0 \n",
        "for i in tokenized_text:\n",
        "  if len(i) >= max_lenth:\n",
        "    max_lenth = len(i)\n",
        "\n",
        "print(max_lenth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgoCy922cTCJ",
        "outputId": "c958ee1f-146e-4f24-8cd5-d2da12c0dfbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "print('padding')\n",
        "MAX_LEN = 100\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n",
        "input_ids = pad_sequences(input_ids, maxlen = MAX_LEN, dtype='long', truncating='post', padding='post')\n",
        "input_ids[0]\n",
        "print('input_ids[0]:',input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk5Q6vcKbzTu",
        "outputId": "03e165df-a08a-4ffe-bb51-57af41c3f727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padding\n",
            "input_ids[0]: [2106 1037 8839 2450 2695 1037 8257 2055 8398 5026 2067 8864 1029    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_masks = []\n",
        " \n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        " \n",
        "print('attention_masks[0]:',attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8OVsAh2gnUa",
        "outputId": "49955697-69bd-4cd0-ad43-3430cecc70e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_masks[0]: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34IXIJOtlt6y",
        "outputId": "d7a47ffd-0494-4994-81d5-69bb04a45bee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5277, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(attention_masks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxrde8tmp79Z",
        "outputId": "a28ef693-357e-4965-ead0-eddd255aa407"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5277"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "sentence_vec = [] \n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                    output_hidden_states = True, \n",
        "                                    )\n",
        "model.eval()\n",
        "\n",
        "for i,j in zip(tqdm(input_ids),attention_masks):\n",
        "  tokens_tensor = torch.tensor([i])\n",
        "  segments_tensors = torch.tensor([j])\n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    hidden_states = outputs[2]\n",
        "\n",
        "  \n",
        "  token_vecs = hidden_states[-2][0]\n",
        "  # # Calculate the average of all 36 token vectors.\n",
        "  sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "  sentence_vec.append(sentence_embedding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ih2vRjqy3o",
        "outputId": "84d0f54f-100a-47e3-8fd2-8574e61f97d0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 5277/5277 [38:44<00:00,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([input_ids[0]])\n",
        "segments_tensors = torch.tensor([attention_masks[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUyJKaTNfo_4",
        "outputId": "c21a55bf-e362-41ec-aa6e-8ab403d6bb8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Wglxh2E9fo9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs"
      ],
      "metadata": {
        "id": "r9GPzjslfo79"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[0][0][0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQuHpg9qfo5w",
        "outputId": "41ba142d-1bee-49a7-f0ef-de859a1744cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers: 3   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 100\n",
            "Number of hidden units: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states[2][0][0][0]\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "metadata": {
        "id": "OVOmlT_ArAfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `hidden_states` has shape [13 x 1 x 36 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [36 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 36 token vectors.\n",
        "sentence_embedding1 = torch.mean(token_vecs, dim=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "fytX9kIJd-I3"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embedding1"
      ],
      "metadata": {
        "id": "yaj-IwAwd-Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = []\n",
        "tmp.append(sentence_embedding)\n",
        "tmp.append(sentence_embedding1)"
      ],
      "metadata": {
        "id": "kxEjcxpZd-En"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18kpOu7g29m_",
        "outputId": "e6f1a6d7-786c-4133-e3dd-313b828d2e30"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(-0.0422), tensor(0.2926)]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##edge 연결 \n",
        "import ast\n",
        "keybert_list = [ast.literal_eval(i) for i in train_df.keybert_keywords]\n",
        "print(len(keybert_list))\n",
        "\n",
        "ner_list = [ast.literal_eval(i) for i in train_df.ner_keywords]\n",
        "print(len(ner_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw3Iv3qXcieD",
        "outputId": "f4185e17-95ca-4518-edfe-0c2969ea3654"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5277\n",
            "5277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dic_array = np.zeros((len(train_df),len(train_df)))\n",
        "print(dic_array.shape)\n",
        "print(dic_array.sum())\n",
        "\n",
        "for i, i_m in enumerate(ner_list):\n",
        "  for j, j_m in enumerate(ner_list):\n",
        "    for item in i_m:\n",
        "      if item in j_m:\n",
        "        dic_array[i][j] = 1 \n",
        "\n",
        "print(dic_array.shape)\n",
        "print(dic_array.sum())\n",
        "\n",
        "for i, i_m in enumerate(keybert_list):\n",
        "  for j, j_m in enumerate(keybert_list):\n",
        "    for item in i_m:\n",
        "      if item in j_m:\n",
        "        dic_array[i][j] = 1 \n",
        "\n",
        "\n",
        "print(dic_array.shape)\n",
        "print(dic_array.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cbaDKH0cli3",
        "outputId": "4d195453-c75e-4ee1-fdcd-91d652491574"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5277, 5277)\n",
            "0.0\n",
            "(5277, 5277)\n",
            "1328495.0\n",
            "(5277, 5277)\n",
            "1382295.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj_t = torch.nonzero(torch.tensor(dic_array)).T\n",
        "print(\"== adj to edge list: \\n\", adj_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDsPQk_6cnRd",
        "outputId": "8e3f623e-c1c2-412f-83af-f661eb653063"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== adj to edge list: \n",
            " tensor([[   0,    0,    0,  ..., 5276, 5276, 5276],\n",
            "        [   0,    5,    7,  ..., 5161, 5176, 5276]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u,v = adj_t[0], adj_t[1]\n",
        "g = dgl.graph((u, v))\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCxFAzzTco2q",
        "outputId": "7a34a5e4-ea59-4bab-923a-0d259abb5d01"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5277, num_edges=1382295,\n",
              "      ndata_schemes={}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['features'] = torch.tensor(int).float()"
      ],
      "metadata": {
        "id": "Y-nKzu1ycqKR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##label 달기\n",
        "labels = train_df.label.values\n",
        "print(len(labels))\n",
        "\n",
        "g.ndata['label'] = torch.tensor(labels)\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOIKmfRsdARr",
        "outputId": "5be9aa84-ab5c-4a03-ebc5-a1c6caa047e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=5277, num_edges=1382295,\n",
              "      ndata_schemes={'features': Scheme(shape=(768,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lnt[0]"
      ],
      "metadata": {
        "id": "liwNzTgy2eO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nids = np.random.permutation(np.arange(g.number_of_nodes()))\n",
        "\n",
        "#test split\n",
        "test_size = int(len(nids) * 0.2)\n",
        "test_id = nids[:test_size]\n",
        "\n",
        "#train, val split\n",
        "train_id = nids[test_size:]\n",
        "val_size = int(len(train_id) * 0.1)\n",
        "\n",
        "train_id = train_id[val_size:]\n",
        "val_id = train_id[:val_size]\n",
        "\n",
        "print(\"train_size: \", len(train_id), \"test_size: \", len(test_id), \"val_size: \", len(val_id) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKkd54rudKd2",
        "outputId": "568f2a49-5575-45f6-8e58-4ad205657475"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size:  3800 test_size:  1055 val_size:  422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from dgl.nn import GraphConv\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats,num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats,h_feat,num_classes):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feat, 'mean')\n",
        "        self.conv3 = SAGEConv(h_feat, num_classes, 'mean')\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(g, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv3(g, h)\n",
        "        return h\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FYl0W4nUdgA0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GCN(g.ndata['features'].shape[1], 64, 2)\n",
        "model = GraphSAGE(g.ndata['features'].shape[1],128, 64,2)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vlItaJVdimb",
        "outputId": "e3a9043a-6dd3-44de-e5de-6bba07a9a9f3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGE(\n",
              "  (conv1): SAGEConv(\n",
              "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "    (fc_self): Linear(in_features=768, out_features=128, bias=False)\n",
              "    (fc_neigh): Linear(in_features=768, out_features=128, bias=False)\n",
              "  )\n",
              "  (conv2): SAGEConv(\n",
              "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "    (fc_self): Linear(in_features=128, out_features=64, bias=False)\n",
              "    (fc_neigh): Linear(in_features=128, out_features=64, bias=False)\n",
              "  )\n",
              "  (conv3): SAGEConv(\n",
              "    (feat_drop): Dropout(p=0.0, inplace=False)\n",
              "    (fc_self): Linear(in_features=64, out_features=2, bias=False)\n",
              "    (fc_neigh): Linear(in_features=64, out_features=2, bias=False)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g,features,labels,train_mask,val_mask):\n",
        "    model.train()\n",
        "\n",
        "    optimizer =  torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    logits = model(g, features)\n",
        "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "    best_val_acc = 0\n",
        "    \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "    #####################################################################\n",
        "    pred = logits.argmax(1)\n",
        "    train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "    val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "\n",
        "    if best_val_acc < val_acc:\n",
        "        best_val_acc = val_acc\n",
        "\n",
        "    return logits, loss, pred, train_acc, val_acc, best_val_acc"
      ],
      "metadata": {
        "id": "_ADTwgjJdkv3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(g,features,labels,test_mask):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "\n",
        "  ############# 5) Your code here ############\n",
        "  # loss function : cross entropy\n",
        "    logits = model(g, features)\n",
        "    loss = F.cross_entropy(logits[test_mask], labels[test_mask])\n",
        "  ##############################################\n",
        "\n",
        "    pred = logits.argmax(1)\n",
        "    test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "    return logits, loss, pred, test_acc"
      ],
      "metadata": {
        "id": "RQYANq7rdyqx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(epoch, g, model,train_id, test_id, val_id): \n",
        "\n",
        "  features = g.ndata['features']\n",
        "  labels = g.ndata['label']\n",
        "  train_mask = train_id\n",
        "  test_mask = test_id\n",
        "  val_mask = val_id\n",
        "\n",
        "\n",
        "  # train\n",
        "  for e in range(epoch):\n",
        "    logits, loss, pred, train_acc, val_acc, best_val_acc = train(g,features,labels,train_mask,val_mask)\n",
        "    print('In epoch {}, loss: {:.3f}, train acc: {:.3f}, val acc: {:.3f} (best {:.3f})'.format(\n",
        "                e, loss, train_acc,val_acc, best_val_acc))\n",
        "\n",
        "\n",
        "  # test\n",
        "  logits, loss, pred, test_acc = test(g,features,labels,test_mask)\n",
        "  print('[Test result] loss: {:.3f}, test acc: {:.3f}'.format(loss, test_acc))\n"
      ],
      "metadata": {
        "id": "GjK2K-Ordz06"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = dgl.add_self_loop(g)"
      ],
      "metadata": {
        "id": "-i5j7eied5mh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(50,g,model,train_id, test_id, val_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUsnifZFd00T",
        "outputId": "f8211f60-4fc2-42b6-b955-f28f38ed716c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 4.640, train acc: 0.510, val acc: 0.505 (best 0.505)\n",
            "In epoch 1, loss: 47.758, train acc: 0.491, val acc: 0.455 (best 0.455)\n",
            "In epoch 2, loss: 6.080, train acc: 0.507, val acc: 0.550 (best 0.550)\n",
            "In epoch 3, loss: 28.293, train acc: 0.491, val acc: 0.455 (best 0.455)\n",
            "In epoch 4, loss: 4.002, train acc: 0.516, val acc: 0.521 (best 0.521)\n",
            "In epoch 5, loss: 19.047, train acc: 0.491, val acc: 0.455 (best 0.455)\n",
            "In epoch 6, loss: 3.842, train acc: 0.518, val acc: 0.543 (best 0.543)\n",
            "In epoch 7, loss: 17.453, train acc: 0.491, val acc: 0.455 (best 0.455)\n",
            "In epoch 8, loss: 2.565, train acc: 0.521, val acc: 0.491 (best 0.491)\n",
            "In epoch 9, loss: 5.037, train acc: 0.493, val acc: 0.455 (best 0.455)\n",
            "In epoch 10, loss: 5.861, train acc: 0.510, val acc: 0.545 (best 0.545)\n",
            "In epoch 11, loss: 2.170, train acc: 0.510, val acc: 0.512 (best 0.512)\n",
            "In epoch 12, loss: 3.945, train acc: 0.508, val acc: 0.538 (best 0.538)\n",
            "In epoch 13, loss: 2.936, train acc: 0.494, val acc: 0.493 (best 0.493)\n",
            "In epoch 14, loss: 4.062, train acc: 0.510, val acc: 0.550 (best 0.550)\n",
            "In epoch 15, loss: 2.207, train acc: 0.501, val acc: 0.474 (best 0.474)\n",
            "In epoch 16, loss: 2.809, train acc: 0.515, val acc: 0.557 (best 0.557)\n",
            "In epoch 17, loss: 2.465, train acc: 0.494, val acc: 0.509 (best 0.509)\n",
            "In epoch 18, loss: 3.649, train acc: 0.514, val acc: 0.547 (best 0.547)\n",
            "In epoch 19, loss: 1.861, train acc: 0.499, val acc: 0.469 (best 0.469)\n",
            "In epoch 20, loss: 3.040, train acc: 0.509, val acc: 0.540 (best 0.540)\n",
            "In epoch 21, loss: 4.247, train acc: 0.497, val acc: 0.486 (best 0.486)\n",
            "In epoch 22, loss: 3.472, train acc: 0.517, val acc: 0.545 (best 0.545)\n",
            "In epoch 23, loss: 3.811, train acc: 0.499, val acc: 0.450 (best 0.450)\n",
            "In epoch 24, loss: 3.392, train acc: 0.506, val acc: 0.538 (best 0.538)\n",
            "In epoch 25, loss: 1.561, train acc: 0.501, val acc: 0.512 (best 0.512)\n",
            "In epoch 26, loss: 2.518, train acc: 0.522, val acc: 0.536 (best 0.536)\n",
            "In epoch 27, loss: 3.333, train acc: 0.487, val acc: 0.467 (best 0.467)\n",
            "In epoch 28, loss: 3.127, train acc: 0.513, val acc: 0.538 (best 0.538)\n",
            "In epoch 29, loss: 2.997, train acc: 0.499, val acc: 0.467 (best 0.467)\n",
            "In epoch 30, loss: 3.246, train acc: 0.513, val acc: 0.552 (best 0.552)\n",
            "In epoch 31, loss: 1.750, train acc: 0.518, val acc: 0.505 (best 0.505)\n",
            "In epoch 32, loss: 2.411, train acc: 0.536, val acc: 0.564 (best 0.564)\n",
            "In epoch 33, loss: 2.441, train acc: 0.497, val acc: 0.453 (best 0.453)\n",
            "In epoch 34, loss: 1.893, train acc: 0.541, val acc: 0.571 (best 0.571)\n",
            "In epoch 35, loss: 2.102, train acc: 0.491, val acc: 0.462 (best 0.462)\n",
            "In epoch 36, loss: 1.904, train acc: 0.529, val acc: 0.547 (best 0.547)\n",
            "In epoch 37, loss: 1.534, train acc: 0.505, val acc: 0.474 (best 0.474)\n",
            "In epoch 38, loss: 1.517, train acc: 0.546, val acc: 0.557 (best 0.557)\n",
            "In epoch 39, loss: 0.934, train acc: 0.535, val acc: 0.505 (best 0.505)\n",
            "In epoch 40, loss: 0.995, train acc: 0.530, val acc: 0.559 (best 0.559)\n",
            "In epoch 41, loss: 1.130, train acc: 0.509, val acc: 0.521 (best 0.521)\n",
            "In epoch 42, loss: 0.732, train acc: 0.547, val acc: 0.533 (best 0.533)\n",
            "In epoch 43, loss: 0.798, train acc: 0.553, val acc: 0.531 (best 0.531)\n",
            "In epoch 44, loss: 1.639, train acc: 0.521, val acc: 0.550 (best 0.550)\n",
            "In epoch 45, loss: 0.754, train acc: 0.564, val acc: 0.564 (best 0.564)\n",
            "In epoch 46, loss: 1.231, train acc: 0.532, val acc: 0.576 (best 0.576)\n",
            "In epoch 47, loss: 1.412, train acc: 0.508, val acc: 0.467 (best 0.467)\n",
            "In epoch 48, loss: 1.004, train acc: 0.563, val acc: 0.583 (best 0.583)\n",
            "In epoch 49, loss: 0.793, train acc: 0.547, val acc: 0.498 (best 0.498)\n",
            "[Test result] loss: 1.005, test acc: 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irDSVSZZd2Ze"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}